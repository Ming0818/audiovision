{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AudioVision - DistinctVoice training data generation\n",
    "*Process:* mono speech wav audio recording is convolved with different impulse responses to generate variants. Variants are then mixed with randome background noises and with other mono speech wav recodings. Base signal remains most dominant in final audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Raw Audio from Wav File\n",
    "audio_file_name = \"violin.wav\"\n",
    "fs, sig = wavfile.read(audio_file_name)\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(sig)\n",
    "plt.title('Original signal')\n",
    "plt.margins(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play original audio\n",
    "ipd.Audio(audio_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impulse Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impulse response in imp_resp directory\n",
    "fs_imp, imp = wavfile.read('imp_resp/imp_resp_1.wav')\n",
    "\n",
    "# Zero padding on impulse reponse\n",
    "imp = np.pad(imp,(0, (sig.size-imp.size)), 'constant')\n",
    "\n",
    "# Time scale definition \n",
    "time=np.linspace(0, len(sig)/fs, num=len(sig))\n",
    "\n",
    "# Play impulse response\n",
    "ipd.Audio('imp_resp/imp_resp_1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Variant Genearation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition to compute convolution\n",
    "def conv(signal, imp_resp):\n",
    "    ## Convolution\n",
    "    sig_fft = np.fft.fft(signal)\n",
    "    imp_fft = np.fft.fft(imp_resp)\n",
    "    convolved_signal = np.fft.ifft(sig_fft*imp_fft).real\n",
    "    ## Normalization\n",
    "    convolved_signal = convolved_signal/max(convolved_signal)\n",
    "    return convolved_signal\n",
    "\n",
    "# Normalized convolution of original signal and impulse reponse\n",
    "conv_sig = conv(sig,imp)\n",
    "\n",
    "# Original signal ans impulse response normalization\n",
    "sig = sig/max(sig)\n",
    "imp = imp/max(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure combined\n",
    "fig, (ax_orig, ax_imp, ax_conv) = plt.subplots(3, 1, sharex=True)\n",
    "ax_orig.plot(sig)\n",
    "ax_orig.set_title('Original signal')\n",
    "ax_orig.margins(0, 0.1)\n",
    "\n",
    "ax_imp.plot(imp)\n",
    "ax_imp.set_title('Impulse response')\n",
    "ax_imp.margins(0, 0.1)\n",
    "\n",
    "ax_conv.plot(conv_sig,color = '#7caeff')\n",
    "ax_conv.plot(sig)\n",
    "ax_conv.set_title('Convolved signal')\n",
    "ax_conv.margins(0, 0.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(11, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 All Audio Variant Genearation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory that will contain all variant audio\n",
    "train_path = \"audio_variant\"\n",
    "if not os.path.exists(train_path):\n",
    "    try:  \n",
    "        os.mkdir(train_path)\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % train_path)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s \" % train_path)\n",
    "\n",
    "for file in os.listdir(\"imp_resp\"):\n",
    "    # Impulse response reading, padding and normalization\n",
    "    fs_imp, imp = wavfile.read(\"imp_resp/\"+file)\n",
    "    imp = np.pad(imp,(0, (sig.size-imp.size)), 'constant')\n",
    "    imp = imp/max(imp)\n",
    "    \n",
    "    # Wav audio variant generation\n",
    "    conv_sig = np.asarray(conv(sig,imp), dtype=np.float32)\n",
    "    variant_file_name = \"./audio_variant/variant-\"+audio_file_name[:-4]+\"-\"+file\n",
    "    wavfile.write(variant_file_name, fs, conv_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Audio Variant Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play first variant computed\n",
    "ipd.Audio(\"./audio_variant/variant-\"+audio_file_name[:-4]+\"-imp_resp_1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 3 Other Audio Variant Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play forth variant computed\n",
    "ipd.Audio(\"./audio_variant/variant-\"+audio_file_name[:-4]+\"-imp_resp_4.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spectrogram Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition to compute spectrogram\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    fmin = 80 # Hz\n",
    "    fmax = 8000 # Hz\n",
    "    freq_slice = np.where((freqs >= fmin) & (freqs <= fmax))\n",
    "    freqs   = freqs[freq_slice]\n",
    "    spec = spec[freq_slice,:][0]\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory that will contain all training spectrograms\n",
    "train_path = \"train_data\"\n",
    "if not os.path.exists(train_path):\n",
    "    try:  \n",
    "        os.mkdir(train_path)\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % train_path)\n",
    "    else:  \n",
    "        print (\"Successfully created the directory %s \" % train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Original Audio Spectrograms _( bin = 1 sec )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute original training spectograms\n",
    "bin_nbr = int(sig.size/fs)\n",
    "\n",
    "for i in range(bin_nbr):\n",
    "    \n",
    "    seg_start = i*fs\n",
    "    seg_end = (1+i)*fs\n",
    "    data = sig[seg_start:seg_end]\n",
    "    _, spectrogram = log_specgram(data, fs)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.axis('off')\n",
    "    filename = train_path+'/spectrogam-'+str(i)+'.jpg'\n",
    "    fig.set_size_inches(4, 4)\n",
    "    fig.savefig(filename, bbox_inches=\"tight\",pad_inches=-0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Varaint Audio Spectrograms _( bin = 1 sec )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all variant training spectrograms\n",
    "for file in os.listdir(\"audio_variant\"):\n",
    "    fs, sig = wavfile.read(\"./audio_variant/\"+file)\n",
    "    bin_nbr = int(sig.size/fs)\n",
    "    for i in range(bin_nbr):\n",
    "        seg_start = i*fs\n",
    "        seg_end = (1+i)*fs\n",
    "\n",
    "        data = sig[seg_start:seg_end]\n",
    "\n",
    "        _, spectrogram = log_specgram(data, fs)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "        plt.axis('off')\n",
    "        filename = train_path+'/spectrogam-'+file[:-4]+'-'+str(i)+'.jpg'\n",
    "        fig.set_size_inches(4, 4)\n",
    "        fig.savefig(filename, bbox_inches=\"tight\",pad_inches=-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
